{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBAC - Regressão II - regressão múltipla\n",
    "\n",
    "## Tarefa I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previsão de renda II\n",
    "\n",
    "Vamos continuar trabalhando com a base 'previsao_de_renda.csv', que é a base do seu próximo projeto. Vamos usar os recursos que vimos até aqui nesta base.\n",
    "\n",
    "|variavel|descrição|\n",
    "|-|-|\n",
    "|data_ref                | Data de referência de coleta das variáveis |\n",
    "|index                   | Código de identificação do cliente|\n",
    "|sexo                    | Sexo do cliente|\n",
    "|posse_de_veiculo        | Indica se o cliente possui veículo|\n",
    "|posse_de_imovel         | Indica se o cliente possui imóvel|\n",
    "|qtd_filhos              | Quantidade de filhos do cliente|\n",
    "|tipo_renda              | Tipo de renda do cliente|\n",
    "|educacao                | Grau de instrução do cliente|\n",
    "|estado_civil            | Estado civil do cliente|\n",
    "|tipo_residencia         | Tipo de residência do cliente (própria, alugada etc)|\n",
    "|idade                   | Idade do cliente|\n",
    "|tempo_emprego           | Tempo no emprego atual|\n",
    "|qt_pessoas_residencia   | Quantidade de pessoas que moram na residência|\n",
    "|renda                   | Renda em reais|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('previsao_de_renda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             15000 non-null  int64  \n",
      " 1   data_ref               15000 non-null  object \n",
      " 2   id_cliente             15000 non-null  int64  \n",
      " 3   sexo                   15000 non-null  object \n",
      " 4   posse_de_veiculo       15000 non-null  bool   \n",
      " 5   posse_de_imovel        15000 non-null  bool   \n",
      " 6   qtd_filhos             15000 non-null  int64  \n",
      " 7   tipo_renda             15000 non-null  object \n",
      " 8   educacao               15000 non-null  object \n",
      " 9   estado_civil           15000 non-null  object \n",
      " 10  tipo_residencia        15000 non-null  object \n",
      " 11  idade                  15000 non-null  int64  \n",
      " 12  tempo_emprego          12427 non-null  float64\n",
      " 13  qt_pessoas_residencia  15000 non-null  float64\n",
      " 14  renda                  15000 non-null  float64\n",
      "dtypes: bool(2), float64(3), int64(4), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento).\n",
    "2. Rode uma regularização *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?\n",
    "3. Faça o mesmo que no passo 2, com uma regressão *LASSO*. Qual método chega a um melhor resultado?\n",
    "4. Rode um modelo *stepwise*. Avalie o $R^2$ na vase de testes. Qual o melhor resultado?\n",
    "5. Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?\n",
    "6. Partindo dos modelos que você ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.\n",
    "7. Ajuste uma árvore de regressão e veja se consegue um $R^2$ melhor com ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X_train: (9320, 24)\n",
      "Shape de X_test: (3107, 24)\n",
      "Shape de y_train: (9320,)\n",
      "Shape de y_test: (3107,)\n"
     ]
    }
   ],
   "source": [
    "# Carregar a base de dados\n",
    "df = pd.read_csv(\"previsao_de_renda.csv\")\n",
    "\n",
    "# Remover colunas desnecessárias\n",
    "df = df.drop(columns=[\"Unnamed: 0\", \"data_ref\", \"id_cliente\"])\n",
    "\n",
    "# Remover valores ausentes\n",
    "df = df.dropna()\n",
    "\n",
    "# Converter variáveis categóricas em dummies\n",
    "df_dummies = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Separar X (variáveis explicativas) e y (variável alvo)\n",
    "X = df_dummies.drop(columns=\"renda\")\n",
    "y = df_dummies[\"renda\"]\n",
    "\n",
    "# Dividir em treino (75%) e teste (25%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Verificar shapes das bases\n",
    "print(\"Shape de X_train:\", X_train.shape)\n",
    "print(\"Shape de X_test:\", X_test.shape)\n",
    "print(\"Shape de y_train:\", y_train.shape)\n",
    "print(\"Shape de y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 0: R² na base de teste = 0.2980\n",
      "Alpha = 0.001: R² na base de teste = 0.2980\n",
      "Alpha = 0.005: R² na base de teste = 0.2980\n",
      "Alpha = 0.01: R² na base de teste = 0.2980\n",
      "Alpha = 0.05: R² na base de teste = 0.2980\n",
      "Alpha = 0.1: R² na base de teste = 0.2980\n",
      "\n",
      "Melhor modelo Ridge: alpha = 0.1 com R² = 0.2980\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Lista de alphas para testar\n",
    "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "# Dicionário para armazenar os R²\n",
    "resultados_ridge = {}\n",
    "\n",
    "# Treinar e avaliar para cada alpha\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    resultados_ridge[alpha] = r2\n",
    "    print(f\"Alpha = {alpha}: R² na base de teste = {r2:.4f}\")\n",
    "\n",
    "# Identificar o melhor alpha\n",
    "melhor_alpha_ridge = max(resultados_ridge, key=resultados_ridge.get)\n",
    "print(f\"\\nMelhor modelo Ridge: alpha = {melhor_alpha_ridge} com R² = {resultados_ridge[melhor_alpha_ridge]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luiza/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/home/luiza/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/luiza/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.036e+11, tolerance: 8.060e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 0: R² na base de teste = 0.2980\n",
      "Alpha = 0.001: R² na base de teste = 0.2980\n",
      "Alpha = 0.005: R² na base de teste = 0.2980\n",
      "Alpha = 0.01: R² na base de teste = 0.2980\n",
      "Alpha = 0.05: R² na base de teste = 0.2980\n",
      "Alpha = 0.1: R² na base de teste = 0.2980\n",
      "\n",
      "Melhor modelo LASSO: alpha = 0.1 com R² = 0.2980\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Lista de alphas para testar\n",
    "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "# Dicionário para armazenar os R²\n",
    "resultados_lasso = {}\n",
    "\n",
    "# Treinar e avaliar para cada alpha\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000)  # aumenta max_iter se necessário\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred = lasso.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    resultados_lasso[alpha] = r2\n",
    "    print(f\"Alpha = {alpha}: R² na base de teste = {r2:.4f}\")\n",
    "\n",
    "# Identificar o melhor alpha\n",
    "melhor_alpha_lasso = max(resultados_lasso, key=resultados_lasso.get)\n",
    "print(f\"\\nMelhor modelo LASSO: alpha = {melhor_alpha_lasso} com R² = {resultados_lasso[melhor_alpha_lasso]:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adicionada: tempo_emprego com p-valor 0.000000\n",
      "Adicionada: sexo_M com p-valor 0.000000\n",
      "Adicionada: tipo_renda_Empresário com p-valor 0.000004\n",
      "Adicionada: idade com p-valor 0.000024\n",
      "Adicionada: educacao_Superior completo com p-valor 0.000804\n",
      "\n",
      "R² na base de teste (Stepwise): 0.2969\n"
     ]
    }
   ],
   "source": [
    "#stepwise\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# Converter todos os dados para float \n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "y_train = y_train.astype(float)\n",
    "y_test = y_test.astype(float)\n",
    "\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_features=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out=0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\"Perform a forward-backward feature selection based on p-value from statsmodels.api.OLS\"\"\"\n",
    "    included = list(initial_features)\n",
    "    while True:\n",
    "        changed = False\n",
    "\n",
    "        # Forward step\n",
    "        excluded = list(set(X.columns) - set(included))\n",
    "        new_pval = pd.Series(index=excluded, dtype=float)\n",
    "        for new_col in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_col]]))).fit()\n",
    "            new_pval[new_col] = model.pvalues[new_col]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed = True\n",
    "            if verbose:\n",
    "                print(f\"Adicionada: {best_feature} com p-valor {best_pval:.6f}\")\n",
    "\n",
    "        # Backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max()  # maior p-valor\n",
    "        if worst_pval > threshold_out:\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            changed = True\n",
    "            if verbose:\n",
    "                print(f\"Removida: {worst_feature} com p-valor {worst_pval:.6f}\")\n",
    "\n",
    "        if not changed:\n",
    "            break\n",
    "\n",
    "    return included\n",
    "\n",
    "# Executar stepwise na base de treinamento\n",
    "selected_features = stepwise_selection(X_train, y_train)\n",
    "\n",
    "# Ajustar modelo final com as variáveis selecionadas\n",
    "X_train_sel = sm.add_constant(X_train[selected_features])\n",
    "X_test_sel = sm.add_constant(X_test[selected_features])\n",
    "modelo_stepwise = sm.OLS(y_train, X_train_sel).fit()\n",
    "\n",
    "# Avaliar R² na base de teste\n",
    "y_pred_stepwise = modelo_stepwise.predict(X_test_sel)\n",
    "r2_stepwise = r2_score(y_test, y_pred_stepwise)\n",
    "\n",
    "print(f\"\\nR² na base de teste (Stepwise): {r2_stepwise:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Ridge     Lasso  Stepwise\n",
      "sexo_M                         6212.241  6211.542  6191.236\n",
      "qt_pessoas_residencia          1456.506  1360.068     0.000\n",
      "estado_civil_Separado          1334.412  1236.266     0.000\n",
      "educacao_Superior completo     1300.310  1256.156   582.120\n",
      "estado_civil_Viúvo             1286.280  1185.255     0.000\n",
      "estado_civil_Solteiro          1055.037   959.150     0.000\n",
      "tipo_renda_Empresário           887.794   887.469   840.551\n",
      "educacao_Secundário             760.247   716.750     0.000\n",
      "educacao_Pós graduação          584.063   485.505     0.000\n",
      "tempo_emprego                   571.107   571.082   570.396\n",
      "posse_de_imovel                 361.232   361.180     0.000\n",
      "educacao_Superior incompleto    337.566   292.402     0.000\n",
      "tipo_renda_Servidor público     127.816   126.944     0.000\n",
      "idade                            40.065    40.070    42.890\n",
      "posse_de_veiculo               -133.340  -132.724     0.000\n",
      "tipo_residencia_Governamental  -235.956  -199.010     0.000\n",
      "tipo_residencia_Casa           -507.923  -474.635     0.000\n",
      "estado_civil_União             -509.274  -508.152     0.000\n",
      "tipo_residencia_Com os pais    -513.591  -478.929     0.000\n",
      "tipo_residencia_Comunitário    -680.763  -631.151     0.000\n",
      "tipo_residencia_Estúdio        -962.277  -914.320     0.000\n",
      "qtd_filhos                    -1338.890 -1242.563     0.000\n",
      "tipo_renda_Bolsista           -1363.629 -1274.800     0.000\n",
      "tipo_renda_Pensionista        -2840.874 -2748.236     0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luiza/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.780e+10, tolerance: 8.060e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/tmp/ipykernel_210473/3094004925.py:14: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[  42.89001763  570.39562878 6191.23569438  840.55134306  582.12025377]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  coef_stepwise_full.update(coef_stepwise)\n"
     ]
    }
   ],
   "source": [
    "# Coeficientes do modelo Ridge\n",
    "ridge_best = Ridge(alpha=0.1)\n",
    "ridge_best.fit(X_train, y_train)\n",
    "coef_ridge = pd.Series(ridge_best.coef_, index=X_train.columns)\n",
    "\n",
    "# Coeficientes do modelo Lasso\n",
    "lasso_best = Lasso(alpha=0.1)\n",
    "lasso_best.fit(X_train, y_train)\n",
    "coef_lasso = pd.Series(lasso_best.coef_, index=X_train.columns)\n",
    "\n",
    "# Coeficientes do modelo Stepwise\n",
    "coef_stepwise = pd.Series(modelo_stepwise.params[1:], index=selected_features)  # ignora o intercepto\n",
    "coef_stepwise_full = pd.Series(0, index=X_train.columns)\n",
    "coef_stepwise_full.update(coef_stepwise)\n",
    "\n",
    "# Juntar tudo em um DataFrame para comparar\n",
    "coef_df = pd.DataFrame({\n",
    "    'Ridge': coef_ridge,\n",
    "    'Lasso': coef_lasso,\n",
    "    'Stepwise': coef_stepwise_full\n",
    "})\n",
    "\n",
    "# Exibir coeficientes diferentes de zero em pelo menos um modelo\n",
    "coef_df_filtrado = coef_df[(coef_df != 0).any(axis=1)]\n",
    "print(coef_df_filtrado.sort_values(by='Ridge', ascending=False).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos Ridge e Lasso apresentaram melhor desempenho em termos de 𝑅2, com vantagem para Lasso na redução de variáveis com baixa relevância. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² com transformações = 0.2983\n"
     ]
    }
   ],
   "source": [
    "# Copiar bases para não alterar original\n",
    "X_train_mod = X_train.copy()\n",
    "X_test_mod = X_test.copy()\n",
    "\n",
    "# Transformações\n",
    "X_train_mod['log_idade'] = np.log1p(X_train_mod['idade'])\n",
    "X_test_mod['log_idade'] = np.log1p(X_test_mod['idade'])\n",
    "\n",
    "X_train_mod['log_tempo_emprego'] = np.log1p(X_train_mod['tempo_emprego'])\n",
    "X_test_mod['log_tempo_emprego'] = np.log1p(X_test_mod['tempo_emprego'])\n",
    "\n",
    "X_train_mod['idade_emprego'] = X_train_mod['idade'] * X_train_mod['tempo_emprego']\n",
    "X_test_mod['idade_emprego'] = X_test_mod['idade'] * X_test_mod['tempo_emprego']\n",
    "\n",
    "X_train_mod['tempo_emprego2'] = X_train_mod['tempo_emprego'] ** 2\n",
    "X_test_mod['tempo_emprego2'] = X_test_mod['tempo_emprego'] ** 2\n",
    "\n",
    "# Rodar Ridge novamente\n",
    "ridge_mod = Ridge(alpha=0.1)\n",
    "ridge_mod.fit(X_train_mod, y_train)\n",
    "y_pred_mod = ridge_mod.predict(X_test_mod)\n",
    "r2_mod = r2_score(y_test, y_pred_mod)\n",
    "\n",
    "print(f\"R² com transformações = {r2_mod:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² da árvore de regressão (max_depth=5): 0.3610\n"
     ]
    }
   ],
   "source": [
    "# Ajustar a árvore\n",
    "tree = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# R²\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "\n",
    "print(f\"R² da árvore de regressão (max_depth=5): {r2_tree:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
